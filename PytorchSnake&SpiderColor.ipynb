{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEJbB9zN3GoqNsiaOhcWxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayBista1010/DeepLearning/blob/main/PytorchSnake%26SpiderColor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvqLM1dASC1L",
        "outputId": "87653d65-e0b4-4c36-8d72-4bfc0c596d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your ZIP file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "\n",
        "# Destination folder in Colab\n",
        "extract_path = '/content/images'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extracted files to {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VJPTvbsSfQy",
        "outputId": "f4691eda-2aec-49ef-df08-3d9ccb797c6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files to /content/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=2):\n",
        "        super().__init__()\n",
        "        # Feature extraction layers\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        )\n",
        "\n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GVqbYIp8UAmy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "CkfIDc6UUd8E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2      # snake/spider\n",
        "learning_rate = 0.001\n",
        "batch_size = 64      # or 64 if memory allows\n",
        "num_epochs = 10      # increase if needed"
      ],
      "metadata": {
        "id": "VDqJIRAIUip0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx_bowvmUvIT",
        "outputId": "6c22bdf7-c0d8-47f1-e54a-3e8cabf80e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "NOvH_NF7dDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'images/'  # contains 'snake' and 'spider' subfolders\n",
        "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print(f\"Classes: {full_dataset.classes}\")  # ['snake', 'spider']"
      ],
      "metadata": {
        "id": "5cV9U70wdbrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "total_size = len(full_dataset)  # 5300 images\n",
        "train_size = int(0.8 * total_size)  # 80% for training\n",
        "test_size = total_size - train_size  # 20% for testing\n",
        "\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n"
      ],
      "metadata": {
        "id": "Iau3WhZVeJys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "EvbFarDZf2sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(in_channels=3, num_classes=num_classes).to(device)"
      ],
      "metadata": {
        "id": "wv4jULrmffJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WiOgOisggoKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "\n",
        "    for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Training accuracy\n",
        "        _, preds = scores.max(1)\n",
        "        correct += (preds == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {avg_loss:.4f} | Train Accuracy: {train_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p-DRX1PxgpiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model, loader_name=\"Data\"):\n",
        "    print(f\"Checking accuracy on {loader_name}\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # evaluation mode\n",
        "\n",
        "    with torch.no_grad():  # no gradient needed\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item()  # convert to number\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    accuracy = 100 * num_correct / num_samples\n",
        "    print(f\"Got {num_correct}/{num_samples} correct -> Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    model.train()  # back to training mode\n",
        "\n",
        "# Usage\n",
        "check_accuracy(train_loader, model, loader_name=\"Training Data\")\n",
        "check_accuracy(test_loader, model, loader_name=\"Test Data\")"
      ],
      "metadata": {
        "id": "LoVXk9sDgzPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}